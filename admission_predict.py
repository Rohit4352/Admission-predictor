# -*- coding: utf-8 -*-
"""admission_predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bJ0YTF052VZspSX9Y671kbuWt354cm6_

# Task 1: Introduction

*  In this project, we have build different regression models to predict the chance of admission into a particular university based on the studentâ€™s profile.
*  INPUTS (features)

  o	GRE scores (out of 340)

  o	TOEFL Scores (out of 120)

  o	University rating (out of 5)

  o	Undergraduate GPA (out of 10)

  o	Statement of purpose( SOP)

  o	Letter of Recommendation (LOR) strength (out of 5)
  
  o	Research experience (either 0 or 1)

*   OUTPUTS (dependent variables)

    o	Chance of admission (ranging from 0 to 1)

# Task 2: Importing Libraries and the Datase
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

#read the dataset
admission_df = pd.read_csv('Admission_predict.csv')
admission_df.head()

#drop the column that doesn't effect the correlation
admission_df.drop('Serial No.', axis= 1, inplace=True)
admission_df.head()

"""# Task 3: Perform Exploratory data analysis"""

admission_df.isnull().sum()

admission_df.info()

admission_df.describe()

df_univ = admission_df.groupby(by  = 'University Rating').mean()
df_univ

"""# Task 4: Perform data visualization"""

#creating histograms
admission_df.hist(bins = 30, figsize=(20,20), color= 'orange')

#correlatoin pair plots
sns.pairplot(admission_df)

"""# Task 5: Create training and testing dataset"""

#create the dependent and independent dataset
X=admission_df.iloc[:,:-1].values
y= admission_df.iloc[:,-1].values

#splitting into training and test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.15, random_state=0)

#feature scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""# Task 6: Train and evaluate a linear regression model"""

from sklearn.linear_model import LinearRegression
linear_reg = LinearRegression()
linear_reg.fit(X_train, y_train)

y_lin_pred = linear_reg.predict(X_test)

"""# Task 7: Train and Evaluate Decision Tress and Random Forest Models"""

from sklearn.tree import DecisionTreeRegressor
Decision_regressor = DecisionTreeRegressor(random_state = 0)
Decision_regressor.fit(X_train, y_train)

y_decision_pred = Decision_regressor.predict(X_test)

from sklearn.ensemble import RandomForestRegressor
Forest_regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)
Forest_regressor.fit(X_train, y_train)

y_forest_pred = Forest_regressor.predict(X_test)

"""# Task 8: Train and evaluate an Artificial Neural Network (ANN)"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Dense, Activation, Dropout
from tensorflow.keras.optimizers import Adam

ANN_model = keras.Sequential()
ANN_model.add(Dense(50, input_dim=7))
ANN_model.add(Activation('relu'))

ANN_model.add(Dense(150))
ANN_model.add(Activation('relu'))
ANN_model.add(Dropout(0.5))

ANN_model.add(Dense(150))
ANN_model.add(Activation('relu'))
ANN_model.add(Dropout(0.5))

ANN_model.add(Dense(50))
ANN_model.add(Activation('linear'))
ANN_model.add(Dense(1))


ANN_model.compile(loss = 'mse', optimizer = 'adam')
ANN_model.summary()

ANN_model.compile(optimizer = 'Adam', loss = 'mean_squared_error')

epochs_hist = ANN_model.fit(X_train, y_train, epochs = 100, batch_size = 20)

y_ann_pred = ANN_model.predict(X_test)
result = ANN_model.evaluate(X_test, y_test)
accuracy_ANN = 1 - result
print("Accuracy : {}".format(accuracy_ANN))

epochs_hist.history.keys()

plt.plot(epochs_hist.history['loss'])
plt.title('Model Loss Progreess During Training')
plt.xlabel('Epoch')
plt.ylabel('Training Loss')
plt.legend(['Training Loss'])

"""# Task 9: Checking the Score of Regressors"""

from sklearn.metrics import accuracy_score
acc_lin = linear_reg.score(X_test, y_test)
print("Liner Accuracy : {}".format(acc_lin))

acc_decision = Decision_regressor.score(X_test, y_test)
print("Decision Accuracy : {}".format(acc_decision))

acc_forest = Forest_regressor.score(X_test, y_test)
print("Forest Accuracy : {}".format(acc_forest))

acc_ANN = 1 - ANN_model.evaluate(X_test, y_test)
print("ANN Accuracy : {}".format(acc_ANN))

"""# Task 10: Plotting the plots"""

plt.figure(figsize= (14,10))
#y_test on x axis
#y_pred on y axis
plt.subplot(221)
plt.plot(y_test, y_lin_pred,'o', color = 'b')
plt.title('Linear plot')

plt.subplot(222)
plt.plot(y_test, y_decision_pred, '^', color = 'r')
plt.title('Decision plot')

plt.subplot(223)
plt.plot(y_test, y_forest_pred, 'v', color = 'g')
plt.title('Forest plot')

plt.subplot(224)
plt.plot(y_test, y_decision_pred, '*', color = 'aqua')
plt.title('ANN plot')

"""#Task 11: Calculate Regression Model KPIs

Model performance metrics

   In regression model, the most commonly known evaluation metrics include:

   * **R-squared (R2)**, which is the proportion of variation in the outcome that is explained by the predictor variables. 
    
    It provides an indication of Goodness Of Fit.
         In multiple regression models, R2 corresponds to the squared correlation between the observed and the predicted values by the model. 
          The Higher the R-squared, the better the model.

* **Adjusted R-squared**, which adjusts the R2 for having too many variables in the model.
        If useless predictors are added to model, the R2 will decrease.
        If useful predictoes are added to model, the R2 will increase.

* Mean Absolute Error (MAE), the MAE measures the prediction error. 
        Mathematically,  MAE = mean(abs(observeds - predicteds))
        MAE is less sensitive to outliers compared to RMSE.
        If MAE is 0, indicates predictions are perfect.

* Mean Squared Error is the average squared difference between the observed actual outome values and the values predicted by the model. 
        Mathematically, MSE = mean((observeds - predicteds)^2)

* Root Mean Squared Error (RMSE), which measures the average error performed by the model in predicting the outcome for an observation. 
        Mathematically, RMSE = sqrt(MSE)
        The lower the RMSE, the better the model.

* Residual Standard Error (RSE), also known as the model sigma, is a variant of the RMSE adjusted for the number of predictors in the model. 
        Mathematically, RSE = abs(observed-predict)
        The lower the RSE, the better the model.
"""

k = X_test.shape[1]
n= len(X_test)
k,n

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from math import sqrt

r2 = r2_score(y_test, y_lin_pred)
adj_r2 = 1- (1-r2)*(n-1)/(n-k-1)
MAE = mean_absolute_error(y_test, y_lin_pred)
MSE = mean_squared_error(y_test, y_lin_pred)
RMSE = float(format(np.sqrt(mean_squared_error(y_test, y_lin_pred)),'.3f'))

print('R2 - ', r2, '\nAdjusted R2 - ', adj_r2, '\nMAE - ', MAE, '\nMSE - ', MSE, '\nRMSE - ', RMSE)